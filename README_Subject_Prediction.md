# Subject Prediction from Academic Abstracts

This project implements a multilingual multi-label text classification system to predict academic subjects from paper abstracts using transformer-based models.

## Project Structure

subject-prediction/
├── data/
│ ├── raw/ # Original JSON data
│ └── processed/ # Preprocessed data files
├── env/ # Virtual environment (excluded in .gitignore)
├── src/
│ ├── data_preparation/
│ │ └── preprocessing.py
│ ├── modeling/
│ │ └── train_model.py
│ └── evaluation/
│ └── evaluate_model.py
├── notebooks/ # Jupyter notebooks for analysis
├── tests/ # Unit tests
├── requirements.txt # Project dependencies
├── README_Subject_Prediction.md # Project documentation
└── .gitignore # Files to ignore in the repo

## Setup and Installation

1. Create and activate a virtual environment:

```bash
python3 -m venv env
source env/bin/activate 

## Dataset Structure

The dataset is structured as newline-delimited JSON (NDJSON), where each line is a separate JSON object. 
This format is suitable for processing large files line-by-line without loading the entire dataset into memory.

## Data Preprocessing

- The data preprocessing pipeline extracts abstracts and subjects, cleans the text, encodes subjects using `MultiLabelBinarizer`, and splits the data into train, validation, and test sets.

**Generated Files:**
- `train.json`: Training data
- `val.json`: Validation data
- `test.json`: Test data
- `label_encoder.pkl`: Serialized label encoder for multi-label classification

**Run the Preprocessing Script:**
```bash
python3 src/data_preparation/data_preprocessing.py